{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6316d0-3b97-4f94-a4ca-ab4f397f48fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a21d9-7d2b-46c5-b0ad-f6cd94fcf6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération du tokenizer pré-entraîné BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1257e0f-1585-40c4-8aba-f821f03f3120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texte à prétraiter par le tokenizer\n",
    "texte = \"Can I find information about SALOME platform?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08cbaf5-c234-43b3-bc10-412839ab6691",
   "metadata": {},
   "source": [
    "## Utilisation globale pour la tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad3ffd-1406-446f-88f1-5e983985fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation globale du tokenizer\n",
    "print(tokenizer(texte))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8673d6f-baee-41d3-a37a-b267298dcb9d",
   "metadata": {},
   "source": [
    "## Séparation des étapes pour la tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaaf0be-5351-4a7d-8b78-626e169e22c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division du texte en tokens\n",
    "tokens = tokenizer.tokenize(texte)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f02c96-6f97-4a96-8e80-089e1b5b482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association des tokens à leur ID respectif (définis par le vocabulaire du tokenizer)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7daead-7853-4ffe-8400-a96469452be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des IDs des tokens spéciaux\n",
    "input_ids = tokenizer.prepare_for_model(ids)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df778d37-a5ad-4112-9421-a1ca4aa7d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des tokens (avec les tokens spéciaux)\n",
    "print(tokenizer.tokenize(tokenizer.decode(input_ids[\"input_ids\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e218765-62e8-44ba-9971-953e86a5347c",
   "metadata": {},
   "source": [
    "## Décodage avec le tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee86362a-f937-4460-b096-9a6b8010940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(input_ids[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98438fd-3b13-4d20-9a06-ff5666bc1768",
   "metadata": {},
   "source": [
    "## Prétraitement de plusieurs textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5548b0d3-34d2-436c-b592-26606101c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sentences = [\n",
    "    \"Can I find information about SALOME platform?\",\n",
    "    \"Where is located CEA Research Center?\",\n",
    "    \"Is it good?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea35b0-7fcb-40e8-a378-685626689835",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs = tokenizer(batch_sentences)\n",
    "print(encoded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2331775d-6946-465b-891e-a92820bfe604",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c30352a-4c30-4878-bf0f-9f7bf0ced2b5",
   "metadata": {},
   "source": [
    "**Padding** is a strategy for ensuring tensors are rectangular by adding a special padding token to shorter sentences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19649e5b-0ce8-41cd-bce2-74e4468a4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs = tokenizer(batch_sentences, padding=True)\n",
    "\n",
    "# Affichage des inputs finaux de chaque phrase\n",
    "print(encoded_inputs)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Affichage des tokens avec le padding\n",
    "print(tokenizer.tokenize(tokenizer.decode(encoded_inputs[\"input_ids\"][0])))\n",
    "print(tokenizer.tokenize(tokenizer.decode(encoded_inputs[\"input_ids\"][1])))\n",
    "print(tokenizer.tokenize(tokenizer.decode(encoded_inputs[\"input_ids\"][2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0551ea-5f66-41b0-bfe3-02fc61656c66",
   "metadata": {},
   "source": [
    "## Truncation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0dac22-4b7a-4f02-84ae-6dd8cde0b1c1",
   "metadata": {},
   "source": [
    "With **truncation**, we can truncate a sequence to the maximum length accepted by the model (if `max_length` not use), or to the maximum length `max_length` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a65c7-ba3d-4dd7-9b7c-25dbc64b2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs = tokenizer(batch_sentences, padding=True, max_length=5, truncation=True)\n",
    "\n",
    "# Affichage des inputs finaux de chaque phrase\n",
    "print(encoded_inputs)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Affichage des tokens avec le padding et la troncation\n",
    "print(tokenizer.tokenize(tokenizer.decode(encoded_inputs[\"input_ids\"][0])))\n",
    "print(tokenizer.tokenize(tokenizer.decode(encoded_inputs[\"input_ids\"][1])))\n",
    "print(tokenizer.tokenize(tokenizer.decode(encoded_inputs[\"input_ids\"][2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67abdd8d-76e0-4d82-ac7a-e610d44c85be",
   "metadata": {},
   "source": [
    "## Construction des tenseurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c714aa3-0267-4a6e-bca8-2387db44e1a6",
   "metadata": {},
   "source": [
    "Pour pouvoir utiliser ces inputs dans un modèle, il faut les placer dans un tenseur. Pour cela, on utilise l'argument `return_tensors` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb67e0-c0b3-40ed-bde0-e771223c587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\") # \"pt\" pour PyTorch\n",
    "\n",
    "# Affichage des inputs finaux de chaque phrase\n",
    "print(encoded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082608cc-6760-427c-b109-75386c3a9e8f",
   "metadata": {},
   "source": [
    "## Décodage avec le tokenizer pour un batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd46de-6127-476b-889e-e2c3a4c95d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des tokens avec le padding avec batch_decode\n",
    "print(tokenizer.batch_decode(encoded_inputs[\"input_ids\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stage-cea-chatbot)",
   "language": "python",
   "name": "stage-cea-chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
